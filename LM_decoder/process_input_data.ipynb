{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, pickle\n",
    "from typing import List, Union, Tuple, Iterable, Optional\n",
    "import json\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform, cosine, cdist\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from madrigal.utils import DATA_DIR\n",
    "\n",
    "kg_encoder = 'hgt'\n",
    "data_source = 'DrugBank'\n",
    "split_method = 'split_by_classes'\n",
    "repeat = None\n",
    "kg_sampling_num_neighbors = None\n",
    "kg_sampling_num_layers = None\n",
    "num_workers = 0\n",
    "\n",
    "use_drug_names = False\n",
    "use_only_label = False\n",
    "concat = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f940a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ddi_info(name, description_df, use_para=True):\n",
    "    if name == 'eval':\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/eval_suffle_df.csv\"\n",
    "    else:\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/{name}_df.csv\"\n",
    "    edge_df = pd.read_csv(os.path.join(DATA_DIR, edgelist_df_fname))\n",
    "\n",
    "    pos_edgelist = edge_df[['head', 'tail']].values     \n",
    "    neg_edgelist1 = edge_df[['head','neg_tail']].values \n",
    "    neg_edgelist2 = edge_df[['neg_head','tail']].values \n",
    "    neg_edgelist = np.concatenate([neg_edgelist1, neg_edgelist2], axis=0)\n",
    "\n",
    "    labels = edge_df['label_indexed'].values \n",
    "    num_labels = max(labels) + 1 if max(labels) > 1 else 1\n",
    "    \n",
    "    tmp_df = pd.DataFrame(pos_edgelist, columns=['drug_index_1', 'drug_index_2'])\n",
    "    merged_df = tmp_df.merge(description_df, on=['drug_index_1', 'drug_index_2'])\n",
    "    \n",
    "    drug_descriptions = merged_df['description'].values\n",
    "    \n",
    "    if use_para:\n",
    "        descriptions = merged_df['paraphrased_descriptions'].values\n",
    "    else:\n",
    "        descriptions = merged_df['generalized_description'].values\n",
    "        \n",
    "    label_text = merged_df[['label']].values\n",
    "            \n",
    "    full_descriptions = np.concatenate((descriptions, descriptions, descriptions))\n",
    "    full_drug_descriptions = np.concatenate([drug_descriptions]*3)\n",
    "    label_text = np.concatenate([label_text]*3)\n",
    "    \n",
    "    edgelist = np.concatenate((pos_edgelist, neg_edgelist))\n",
    "    labels = np.concatenate((labels, labels, labels))\n",
    "    pos_neg = np.concatenate((np.ones((pos_edgelist.shape[0])), np.zeros((neg_edgelist1.shape[0])), np.zeros((neg_edgelist2.shape[0]))))\n",
    "    \n",
    "    return full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, description_df, label_text\n",
    "\n",
    "#description_df = pd.read_csv(os.path.join(path_base, 'polypharmacy_new/DrugBank/drugbank_ddi_directed_final_cleaned.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e785da5b",
   "metadata": {},
   "source": [
    "## Paraphrased replace neg drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56473cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_descriptions(description_df, paraphrase_file, how='rephrase'):\n",
    "    \n",
    "    unique_ddis = description_df['generalized_description'].unique()\n",
    "    data = []\n",
    "    \n",
    "    RESULTS_FILENAMES = [paraphrase_file]\n",
    "\n",
    "    for result_filename in RESULTS_FILENAMES:\n",
    "        with open(result_filename, \"r\") as f:\n",
    "            for line_num, line in enumerate(f):\n",
    "                try:\n",
    "                    json_object = json.loads(line)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(line_num)\n",
    "                    print(line)\n",
    "                    raise\n",
    "\n",
    "                try:\n",
    "                    # Note: this is how the openai_api_request_parallel_processor.py has been amended to save results (along with the request and idx)\n",
    "\n",
    "                    idx, request, response = json_object[0]['idx'], json_object[0]['request'], json_object[1]\n",
    "                    prompt = request['messages'][1]['content']\n",
    "\n",
    "                    if how not in prompt:\n",
    "                        continue\n",
    "\n",
    "                    row = {\n",
    "                        'id': unique_ddis[idx]\n",
    "                    }\n",
    "\n",
    "                    for choice in response['choices']:\n",
    "                        i = choice['index']\n",
    "\n",
    "                        response_text = choice['message']['content']\n",
    "                        row[f\"text_{i}\"] = response_text\n",
    "\n",
    "                    data.append(row)\n",
    "\n",
    "                except TypeError:\n",
    "                    print(line_num)\n",
    "                    print(request)\n",
    "                    print(response)\n",
    "\n",
    "                except KeyError:\n",
    "                    print(line_num)\n",
    "                    print(request)\n",
    "                    print(response)\n",
    "                    raise\n",
    "    return {d['id']: d['text_0'] for d in data}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f65a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df = pd.read_csv(os.path.join(DATA_DIR, 'polypharmacy_new/DrugBank/drugbank_ddi_directed_final_cleaned.tsv'))\n",
    "\n",
    "paraphrased_descriptions = []\n",
    "paraphrase_file = './api_requests_results_new.jsonl'\n",
    "replace_dict = replace_descriptions(description_df, paraphrase_file, how='extend')\n",
    "for i in range(description_df.shape[0]):\n",
    "    description = description_df.at[description_df.index[i], 'generalized_description']\n",
    "    paraphrased_descriptions.append(replace_dict[description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330c49c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df['paraphrased_descriptions'] = paraphrased_descriptions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca6b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ddi_info(name, description_df, use_para=True):\n",
    "    if name == 'eval':\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/eval_suffle_df.csv\"\n",
    "    else:\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/{name}_df.csv\"\n",
    "    edge_df = pd.read_csv(os.path.join(DATA_DIR, edgelist_df_fname))\n",
    "\n",
    "    pos_edgelist = edge_df[['head', 'tail']].values     \n",
    "    neg_edgelist1 = edge_df[['head','neg_tail']].values \n",
    "    neg_edgelist2 = edge_df[['neg_head','tail']].values \n",
    "    neg_edgelist = np.concatenate([neg_edgelist1, neg_edgelist2], axis=0)\n",
    "\n",
    "    labels = edge_df['label_indexed'].values \n",
    "    num_labels = max(labels) + 1 if max(labels) > 1 else 1\n",
    "    \n",
    "    tmp_df = pd.DataFrame(pos_edgelist, columns=['drug_index_1', 'drug_index_2'])\n",
    "    merged_df = tmp_df.merge(description_df, on=['drug_index_1', 'drug_index_2'])\n",
    "    \n",
    "    drug_descriptions = merged_df['description'].values\n",
    "    \n",
    "    if use_para:\n",
    "        descriptions = merged_df['paraphrased_descriptions'].values\n",
    "    else:\n",
    "        descriptions = merged_df['generalized_description'].values\n",
    "            \n",
    "    full_descriptions = np.concatenate((descriptions, descriptions, descriptions))\n",
    "    full_drug_descriptions = np.concatenate([drug_descriptions]*3)\n",
    "    \n",
    "    edgelist = np.concatenate((pos_edgelist, neg_edgelist))\n",
    "    labels = np.concatenate((labels, labels, labels))\n",
    "    pos_neg = np.concatenate((np.ones((pos_edgelist.shape[0])), np.zeros((neg_edgelist1.shape[0])), np.zeros((neg_edgelist2.shape[0]))))\n",
    "    \n",
    "    return full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, description_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13912b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_df_para(split):\n",
    "    full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, merged_df = get_ddi_info(split, \n",
    "                                                                                                   description_df, \n",
    "                                                                                                   use_para=True)\n",
    "    \n",
    "    head_to_name = merged_df[['drug_index_1', 'name_1']].drop_duplicates(subset='drug_index_1', keep='first')\n",
    "    tail_to_name = merged_df[['drug_index_2', 'name_2']].drop_duplicates(subset='drug_index_2', keep='first')\n",
    "    tail_to_name = tail_to_name.rename(columns={'drug_index_2': 'drug_index_1', 'name_2': 'name_1'})\n",
    "    full_to_name = pd.concat([head_to_name, tail_to_name], ignore_index=True)\n",
    "    all_descriptions = []\n",
    "\n",
    "    for i in tqdm(range(len(edgelist))):\n",
    "        drug1, drug2 = edgelist[i,:]\n",
    "        \n",
    "        drug1_name = full_to_name[full_to_name['drug_index_1'] == drug1]['name_1'].tolist()[0]\n",
    "        drug2_name = full_to_name[full_to_name['drug_index_1'] == drug2]['name_1'].tolist()[0]\n",
    "        description = full_descriptions[i]\n",
    "        description_with_drugs = description.replace(\"@Drug1\", drug1_name).replace(\"@Drug2\", drug2_name)\n",
    "        all_descriptions.append(description_with_drugs)\n",
    "\n",
    "    full_drug_descriptions = all_descriptions\n",
    "    \n",
    "    df = pd.DataFrame({'head': edgelist[:,0], 'tail': edgelist[:,1], 'labels': labels, 'pos_neg': pos_neg,\n",
    "                  'descriptions': full_descriptions, 'drug_descriptions': full_drug_descriptions})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985aca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = get_new_df_para('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db80e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_new_df_para('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45381f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_new_df_para('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246a0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.concat([val_df, test_df], ignore_index=True)\n",
    "eval_df = eval_df.sample(frac=1).reset_index(drop=True)\n",
    "eval_df.to_csv('./augmented_dataset/eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdd344",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df.to_csv('./augmented_dataset/train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05489072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def get_new_df(split):\n",
    "    full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, merged_df = get_ddi_info(split)\n",
    "    neg_mask = pos_neg == 0\n",
    "    neg_edges = edgelist[neg_mask,:]\n",
    "    neg_full_descriptions = full_descriptions[neg_mask]\n",
    "\n",
    "    head_to_name = merged_df[['drug_index_1', 'name_1']].drop_duplicates(subset='drug_index_1', keep='first')\n",
    "    tail_to_name = merged_df[['drug_index_2', 'name_2']].drop_duplicates(subset='drug_index_2', keep='first')\n",
    "    tail_to_name = tail_to_name.rename(columns={'drug_index_2': 'drug_index_1', 'name_2': 'name_1'})\n",
    "    full_to_name = pd.concat([head_to_name, tail_to_name], ignore_index=True)\n",
    "    neg_descriptions = []\n",
    "\n",
    "    for i in tqdm(range(len(neg_edges))):\n",
    "        drug1, drug2 = neg_edges[i,:]\n",
    "        \n",
    "        drug1_name = full_to_name[full_to_name['drug_index_1'] == drug1]['name_1'].tolist()[0]\n",
    "        drug2_name = full_to_name[full_to_name['drug_index_1'] == drug2]['name_1'].tolist()[0]\n",
    "        description = neg_full_descriptions[i]\n",
    "        description_with_drugs = description.replace(\"@Drug1\", drug1_name).replace(\"@Drug2\", drug2_name)\n",
    "        neg_descriptions.append(description_with_drugs)\n",
    "\n",
    "    full_drug_descriptions[neg_mask] = neg_descriptions\n",
    "    \n",
    "    df = pd.DataFrame({'head': edgelist[:,0], 'tail': edgelist[:,1], 'labels': labels, 'pos_neg': pos_neg,\n",
    "                  'descriptions': full_descriptions, 'drug_descriptions': full_drug_descriptions})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2601ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = get_new_df('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = get_new_df('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba4379",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_new_df('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b6a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.concat([val_df, test_df], ignore_index=True)\n",
    "eval_df = eval_df.sample(frac=1).reset_index(drop=True)\n",
    "eval_df.to_csv('./dataset/eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc76a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df.to_csv('./dataset/train_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08f120e",
   "metadata": {},
   "source": [
    "## Corrupted (rev direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad344b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_to_keep = ['gastrointestinal ulceration, gastrointestinal irritation, increase',\n",
    "                  'renal failure, hypotension, increase',\n",
    "                  'hypotension, Electrolyte Disturbance, increase',\n",
    "                  'hypertension, increase',\n",
    "                  'serum level of the active metabolites, increase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d09a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_eval_df = pd.read_csv('./label_dataset/eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "356a68dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_descriptions\n",
       "hypertension, increase                                                  0.437342\n",
       "methemoglobinemia, increase                                             0.317109\n",
       "nephrotoxicity, increase                                                0.128223\n",
       "gastrointestinal bleeding, increase                                     0.061125\n",
       "neuroexcitatory, increase                                               0.035104\n",
       "analgesic, increase                                                     0.012509\n",
       "serum level of the active metabolites, increase                         0.004158\n",
       "bioavailability, increase                                               0.000935\n",
       "gastrointestinal ulceration, gastrointestinal irritation, increase      0.000665\n",
       "hypotension, Electrolyte Disturbance, increase                          0.000541\n",
       "serum level of the active metabolites, decrease | efficacy, decrease    0.000473\n",
       "renal failure, hypotension, increase                                    0.000451\n",
       "bleeding, thrombocytopenia, increase                                    0.000451\n",
       "thrombocytopenia, increase                                              0.000417\n",
       "hypertension, tardive dyskinesia, increase                              0.000259\n",
       "sedation, decrease                                                      0.000237\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_eval_df['label_descriptions'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12932a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_eval_df = label_eval_df[label_eval_df['label_descriptions'].isin(classes_to_keep)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "606570a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_descriptions\n",
       "hypertension, increase                                                0.986878\n",
       "serum level of the active metabolites, increase                       0.009384\n",
       "gastrointestinal ulceration, gastrointestinal irritation, increase    0.001500\n",
       "hypotension, Electrolyte Disturbance, increase                        0.001221\n",
       "renal failure, hypotension, increase                                  0.001017\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_eval_df['label_descriptions'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630dbdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = label_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07937d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_pos = eval_df[eval_df['pos_neg'] == 1.0]\n",
    "eval_df_pos.to_csv('./reversed_dataset/eval_df_pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c00d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_neg = eval_df[eval_df['pos_neg'] == 0.0]\n",
    "eval_df_neg.to_csv('./reversed_dataset/eval_df_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "803af55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted = []\n",
    "for i in range(eval_df_pos.shape[0]):\n",
    "    desc = eval_df_pos.loc[eval_df_pos.index[i], \"descriptions\"]\n",
    "    \n",
    "    if 'increase' in desc:\n",
    "        desc = desc.replace('increase', 'decrease')\n",
    "    elif 'decrease' in desc:\n",
    "        desc = desc.replace('decrease', 'increase')\n",
    "    elif 'reduced' in desc:\n",
    "        desc = desc.replace('reduced', 'increased')\n",
    "    \n",
    "    corrupted.append(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52dbdb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_rev = eval_df_pos.copy()\n",
    "eval_df_rev['descriptions'] = corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfc4615f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df_rev.to_csv('./reversed_dataset/eval_df_pos_rev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194577bd",
   "metadata": {},
   "source": [
    "## Only label df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a453f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_df(split, description_df):\n",
    "    full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, description_df, label_text = get_ddi_info(split, \n",
    "                                                                                                                    description_df, \n",
    "                                                                                                                    use_para=False)\n",
    "    df = pd.DataFrame({'head': edgelist[:,0], 'tail': edgelist[:,1], 'labels': labels, 'pos_neg': pos_neg,\n",
    "                  'descriptions': full_descriptions, 'label_descriptions': label_text[:,0]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd2c0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_new_df('train', description_df)\n",
    "val_df = get_new_df('val', description_df)\n",
    "test_df = get_new_df('test', description_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ac54786",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.concat([val_df, test_df], ignore_index=True)\n",
    "eval_df = eval_df.sample(frac=1).reset_index(drop=True)\n",
    "eval_df.to_csv('./label_dataset/eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93df2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df.to_csv('./label_dataset/train_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0e191",
   "metadata": {},
   "source": [
    "## Paraphrase df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff202b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_descriptions(description_df, paraphrase_file, how='rephrase'):\n",
    "    \n",
    "    unique_ddis = description_df['generalized_description'].unique()\n",
    "    data = []\n",
    "    \n",
    "    RESULTS_FILENAMES = [paraphrase_file]\n",
    "\n",
    "    for result_filename in RESULTS_FILENAMES:\n",
    "        with open(result_filename, \"r\") as f:\n",
    "            for line_num, line in enumerate(f):\n",
    "                try:\n",
    "                    json_object = json.loads(line)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(line_num)\n",
    "                    print(line)\n",
    "                    raise\n",
    "\n",
    "                try:\n",
    "                    # Note: this is how the openai_api_request_parallel_processor.py has been amended to save results (along with the request and idx)\n",
    "\n",
    "                    idx, request, response = json_object[0]['idx'], json_object[0]['request'], json_object[1]\n",
    "                    prompt = request['messages'][1]['content']\n",
    "\n",
    "                    if how not in prompt:\n",
    "                        continue\n",
    "\n",
    "                    row = {\n",
    "                        'id': unique_ddis[idx]\n",
    "                    }\n",
    "\n",
    "                    for choice in response['choices']:\n",
    "                        i = choice['index']\n",
    "\n",
    "                        response_text = choice['message']['content']\n",
    "                        row[f\"text_{i}\"] = response_text\n",
    "\n",
    "                    data.append(row)\n",
    "\n",
    "                except TypeError:\n",
    "                    print(line_num)\n",
    "                    print(request)\n",
    "                    print(response)\n",
    "\n",
    "                except KeyError:\n",
    "                    print(line_num)\n",
    "                    print(request)\n",
    "                    print(response)\n",
    "                    raise\n",
    "    return {d['id']: d['text_0'] for d in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e44b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df = pd.read_csv(os.path.join(DATA_DIR, 'polypharmacy_new/DrugBank/drugbank_ddi_directed_final_cleaned.tsv'))\n",
    "\n",
    "paraphrased_descriptions = []\n",
    "paraphrase_file = './api_requests_results_multi_new.jsonl'\n",
    "replace_dict = replace_descriptions(description_df, paraphrase_file, how='extend')\n",
    "for i in range(description_df.shape[0]):\n",
    "    description = description_df.at[description_df.index[i], 'generalized_description']\n",
    "    paraphrased_descriptions.append(replace_dict[description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e26eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_before_word(s, word):\n",
    "    # Check if the word is in the string\n",
    "    if word in s:\n",
    "        # Split the string at the first occurrence of the word\n",
    "        parts = s.split(word, 1)\n",
    "        # Return the part after the word, including the word itself\n",
    "        return word + parts[1]\n",
    "    else:\n",
    "        # If the word is not in the string, return the original string or handle as needed\n",
    "        return s\n",
    "\n",
    "def delete_after_word(text, word):\n",
    "    # Splitting the text at the specified word. The result is a list.\n",
    "    parts = text.split(word, 1)  # The '1' indicates we want to split at the first occurrence only.\n",
    "    \n",
    "    # If the word is found, parts[0] will contain the text before the word.\n",
    "    # We return this part along with the word itself, assuming you want to keep the word after which everything is deleted.\n",
    "    if len(parts) > 1:\n",
    "        return parts[0] + word\n",
    "    else:\n",
    "        # If the word is not found, return the original text\n",
    "        return text\n",
    "    \n",
    "def process_text(text):\n",
    "    \n",
    "    text = delete_before_word(text, '\"medical')\n",
    "    text = delete_after_word(text, '}')\n",
    "    text = \"{\" + text\n",
    "    text = text.replace('”', '\"')\n",
    "    return eval(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d253028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_descriptions = [process_text(i) for i in paraphrased_descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e5cc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dicts_to_dict_of_lists(list_of_dicts):\n",
    "    # Initialize the output dictionary\n",
    "    dict_of_lists = {}\n",
    "    # Iterate over each dictionary in the list\n",
    "    for dictionary in list_of_dicts:\n",
    "        for key, value in dictionary.items():\n",
    "            # If the key doesn't exist in the output dictionary, initialize it with an empty list\n",
    "            if key not in dict_of_lists:\n",
    "                dict_of_lists[key] = []\n",
    "            # Append the current value to the list corresponding to the current key\n",
    "            dict_of_lists[key].append(value)\n",
    "    return dict_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ab62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_descriptions_dict = list_of_dicts_to_dict_of_lists(paraphrased_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0733690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_descriptions_df = pd.DataFrame.from_dict(paraphrased_descriptions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a0c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df = pd.concat([description_df, paraphrased_descriptions_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ddi_info(name, description_df, use_para=True):\n",
    "    if name == 'eval':\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/eval_suffle_df.csv\"\n",
    "    else:\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/{name}_df.csv\"\n",
    "    edge_df = pd.read_csv(os.path.join(DATA_DIR, edgelist_df_fname))\n",
    "\n",
    "    pos_edgelist = edge_df[['head', 'tail']].values     \n",
    "    neg_edgelist1 = edge_df[['head','neg_tail']].values \n",
    "    neg_edgelist2 = edge_df[['neg_head','tail']].values \n",
    "    neg_edgelist = np.concatenate([neg_edgelist1, neg_edgelist2], axis=0)\n",
    "\n",
    "    labels = edge_df['label_indexed'].values \n",
    "    num_labels = max(labels) + 1 if max(labels) > 1 else 1\n",
    "    \n",
    "    tmp_df = pd.DataFrame(pos_edgelist, columns=['drug_index_1', 'drug_index_2'])\n",
    "    merged_df = tmp_df.merge(description_df, on=['drug_index_1', 'drug_index_2'])\n",
    "    \n",
    "    drug_descriptions = merged_df['description'].values\n",
    "    \n",
    "    if use_para:\n",
    "        descriptions = merged_df[['generalized_description',\n",
    "                                  'medical_doctor_1', 'medical_doctor_2','medical_doctor_3', \n",
    "                                  'pharmacologist_1', 'pharmacologist_2','pharmacologist_3', \n",
    "                                  'toxicologist_1', 'toxicologist_2', 'toxicologist_3']].values\n",
    "    else:\n",
    "        descriptions = merged_df['generalized_description'].values\n",
    "        \n",
    "    label_text = merged_df[['label']].values\n",
    "            \n",
    "    full_descriptions = np.concatenate((descriptions, descriptions, descriptions))\n",
    "    full_drug_descriptions = np.concatenate([drug_descriptions]*3)\n",
    "    label_text = np.concatenate([label_text]*3)\n",
    "    \n",
    "    edgelist = np.concatenate((pos_edgelist, neg_edgelist))\n",
    "    labels = np.concatenate((labels, labels, labels))\n",
    "    pos_neg = np.concatenate((np.ones((pos_edgelist.shape[0])), np.zeros((neg_edgelist1.shape[0])), np.zeros((neg_edgelist2.shape[0]))))\n",
    "    \n",
    "    return full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, description_df, label_text\n",
    "\n",
    "#description_df = pd.read_csv(os.path.join(path_base, 'polypharmacy_new/DrugBank/drugbank_ddi_directed_final_cleaned.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b2e4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_df(split, description_df):\n",
    "    full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, description_df, label_text = get_ddi_info(split, \n",
    "                                                                                                                    description_df, \n",
    "                                                                                                                    use_para=True)\n",
    "    df = pd.DataFrame({'head': edgelist[:,0], 'tail': edgelist[:,1], 'labels': labels, 'pos_neg': pos_neg,\n",
    "                       'descriptions_0': full_descriptions[:,0], 'label_descriptions': label_text[:,0], \n",
    "                       'descriptions_1': full_descriptions[:,1],\n",
    "                       'descriptions_2': full_descriptions[:,2],\n",
    "                       'descriptions_3': full_descriptions[:,3],\n",
    "                       'descriptions_4': full_descriptions[:,4],\n",
    "                       'descriptions_5': full_descriptions[:,5],\n",
    "                       'descriptions_6': full_descriptions[:,6],\n",
    "                       'descriptions_7': full_descriptions[:,7],\n",
    "                       'descriptions_8': full_descriptions[:,8],\n",
    "                       'descriptions_9': full_descriptions[:,9]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95e523ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_new_df('train', description_df)\n",
    "val_df = get_new_df('val', description_df)\n",
    "test_df = get_new_df('test', description_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "711dd32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.concat([val_df, test_df], ignore_index=True)\n",
    "eval_df = eval_df.sample(frac=1).reset_index(drop=True)\n",
    "eval_df.to_csv('./paraphrased_dataset_new/eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "068b3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df.to_csv('./paraphrased_dataset_new/train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9eed3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed2aad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein_new",
   "language": "python",
   "name": "protein_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
