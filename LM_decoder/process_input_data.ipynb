{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705d5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, pickle\n",
    "from typing import List, Union, Tuple, Iterable, Optional\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.spatial.distance import pdist, squareform, cosine, cdist\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from madrigal.utils import DATA_DIR\n",
    "\n",
    "kg_encoder = 'hgt'\n",
    "data_source = 'DrugBank'\n",
    "split_method = 'split_by_classes'\n",
    "repeat = None\n",
    "kg_sampling_num_neighbors = None\n",
    "kg_sampling_num_layers = None\n",
    "num_workers = 0\n",
    "\n",
    "use_drug_names = False\n",
    "use_only_label = False\n",
    "concat = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f940a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ddi_info(name, description_df, use_para=True):\n",
    "    if name == 'eval':\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/eval_suffle_df.csv\"\n",
    "    else:\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/{name}_df.csv\"\n",
    "    edge_df = pd.read_csv(os.path.join(DATA_DIR, edgelist_df_fname))\n",
    "\n",
    "    pos_edgelist = edge_df[['head', 'tail']].values     \n",
    "    neg_edgelist1 = edge_df[['head','neg_tail']].values \n",
    "    neg_edgelist2 = edge_df[['neg_head','tail']].values \n",
    "    neg_edgelist = np.concatenate([neg_edgelist1, neg_edgelist2], axis=0)\n",
    "\n",
    "    labels = edge_df['label_indexed'].values \n",
    "    num_labels = max(labels) + 1 if max(labels) > 1 else 1\n",
    "    \n",
    "    tmp_df = pd.DataFrame(pos_edgelist, columns=['drug_index_1', 'drug_index_2'])\n",
    "    merged_df = tmp_df.merge(description_df, on=['drug_index_1', 'drug_index_2'])\n",
    "    \n",
    "    drug_descriptions = merged_df['description'].values\n",
    "    \n",
    "    if use_para:\n",
    "        descriptions = merged_df['paraphrased_descriptions'].values\n",
    "    else:\n",
    "        descriptions = merged_df['generalized_description'].values\n",
    "        \n",
    "    label_text = merged_df[['label']].values\n",
    "            \n",
    "    full_descriptions = np.concatenate((descriptions, descriptions, descriptions))\n",
    "    full_drug_descriptions = np.concatenate([drug_descriptions]*3)\n",
    "    label_text = np.concatenate([label_text]*3)\n",
    "    \n",
    "    edgelist = np.concatenate((pos_edgelist, neg_edgelist))\n",
    "    labels = np.concatenate((labels, labels, labels))\n",
    "    pos_neg = np.concatenate((np.ones((pos_edgelist.shape[0])), np.zeros((neg_edgelist1.shape[0])), np.zeros((neg_edgelist2.shape[0]))))\n",
    "    \n",
    "    return full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, label_text\n",
    "\n",
    "description_df = pd.read_csv(os.path.join(DATA_DIR, 'polypharmacy_new/DrugBank/drugbank_ddi_directed_final_cleaned.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194577bd",
   "metadata": {},
   "source": [
    "## Only Drugbank descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a453f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_df(split, description_df):\n",
    "    full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, label_text = get_ddi_info(split, description_df, use_para=False)\n",
    "    df = pd.DataFrame({'head': edgelist[:,0], 'tail': edgelist[:,1], 'labels': labels, 'pos_neg': pos_neg, 'descriptions': full_descriptions, 'label_descriptions': label_text[:,0]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd2c0a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_new_df('train', description_df)\n",
    "val_df = get_new_df('val', description_df)\n",
    "test_df = get_new_df('test', description_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ac54786",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.concat([val_df, test_df], ignore_index=True)\n",
    "eval_df = eval_df.sample(frac=1).reset_index(drop=True)\n",
    "eval_df.to_csv('./label_dataset/eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "93df2dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df.to_csv('./label_dataset/train_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0e191",
   "metadata": {},
   "source": [
    "## Paraphrased descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff202b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_descriptions(description_df, paraphrase_file, how='rephrase'):\n",
    "    \n",
    "    unique_ddis = description_df['generalized_description'].unique()\n",
    "    data = []\n",
    "    \n",
    "    RESULTS_FILENAMES = [paraphrase_file]\n",
    "\n",
    "    for result_filename in RESULTS_FILENAMES:\n",
    "        with open(result_filename, \"r\") as f:\n",
    "            for line_num, line in enumerate(f):\n",
    "                try:\n",
    "                    json_object = json.loads(line)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(line_num)\n",
    "                    print(line)\n",
    "                    raise\n",
    "\n",
    "                try:\n",
    "                    # Note: this is how the openai_api_request_parallel_processor.py has been amended to save results (along with the request and idx)\n",
    "\n",
    "                    idx, request, response = json_object[0]['idx'], json_object[0]['request'], json_object[1]\n",
    "                    prompt = request['messages'][1]['content']\n",
    "\n",
    "                    if how not in prompt:\n",
    "                        continue\n",
    "\n",
    "                    row = {\n",
    "                        'id': unique_ddis[idx]\n",
    "                    }\n",
    "\n",
    "                    for choice in response['choices']:\n",
    "                        i = choice['index']\n",
    "\n",
    "                        response_text = choice['message']['content']\n",
    "                        row[f\"text_{i}\"] = response_text\n",
    "\n",
    "                    data.append(row)\n",
    "\n",
    "                except TypeError:\n",
    "                    print(line_num)\n",
    "                    print(request)\n",
    "                    print(response)\n",
    "\n",
    "                except KeyError:\n",
    "                    print(line_num)\n",
    "                    print(request)\n",
    "                    print(response)\n",
    "                    raise\n",
    "    return {d['id']: d['text_0'] for d in data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e44b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df = pd.read_csv(os.path.join(DATA_DIR, 'polypharmacy_new/DrugBank/drugbank_ddi_directed_final_cleaned.tsv'))\n",
    "\n",
    "paraphrased_descriptions = []\n",
    "paraphrase_file = './api_requests_results_multi_new.jsonl'\n",
    "replace_dict = replace_descriptions(description_df, paraphrase_file, how='extend')\n",
    "for i in range(description_df.shape[0]):\n",
    "    description = description_df.at[description_df.index[i], 'generalized_description']\n",
    "    paraphrased_descriptions.append(replace_dict[description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_before_word(s, word):\n",
    "    # Check if the word is in the string\n",
    "    if word in s:\n",
    "        # Split the string at the first occurrence of the word\n",
    "        parts = s.split(word, 1)\n",
    "        # Return the part after the word, including the word itself\n",
    "        return word + parts[1]\n",
    "    else:\n",
    "        # If the word is not in the string, return the original string or handle as needed\n",
    "        return s\n",
    "\n",
    "def delete_after_word(text, word):\n",
    "    # Splitting the text at the specified word. The result is a list.\n",
    "    parts = text.split(word, 1)  # The '1' indicates we want to split at the first occurrence only.\n",
    "    \n",
    "    # If the word is found, parts[0] will contain the text before the word.\n",
    "    # We return this part along with the word itself, assuming you want to keep the word after which everything is deleted.\n",
    "    if len(parts) > 1:\n",
    "        return parts[0] + word\n",
    "    else:\n",
    "        # If the word is not found, return the original text\n",
    "        return text\n",
    "    \n",
    "def process_text(text):\n",
    "    text = delete_before_word(text, '\"medical')\n",
    "    text = delete_after_word(text, '}')\n",
    "    text = \"{\" + text\n",
    "    text = text.replace('â€', '\"')\n",
    "    return eval(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d253028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_descriptions = [process_text(i) for i in paraphrased_descriptions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e5cc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of_dicts_to_dict_of_lists(list_of_dicts):\n",
    "    # Initialize the output dictionary\n",
    "    dict_of_lists = {}\n",
    "    # Iterate over each dictionary in the list\n",
    "    for dictionary in list_of_dicts:\n",
    "        for key, value in dictionary.items():\n",
    "            # If the key doesn't exist in the output dictionary, initialize it with an empty list\n",
    "            if key not in dict_of_lists:\n",
    "                dict_of_lists[key] = []\n",
    "            # Append the current value to the list corresponding to the current key\n",
    "            dict_of_lists[key].append(value)\n",
    "    return dict_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88ab62fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_descriptions_dict = list_of_dicts_to_dict_of_lists(paraphrased_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0733690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrased_descriptions_df = pd.DataFrame.from_dict(paraphrased_descriptions_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53a0c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_df = pd.concat([description_df, paraphrased_descriptions_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8868d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ddi_info(name, description_df, use_para=True):\n",
    "    if name == 'eval':\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/eval_suffle_df.csv\"\n",
    "    else:\n",
    "        edgelist_df_fname = f\"polypharmacy_new/{data_source}/{split_method}/{name}_df.csv\"\n",
    "    edge_df = pd.read_csv(os.path.join(DATA_DIR, edgelist_df_fname))\n",
    "\n",
    "    pos_edgelist = edge_df[['head', 'tail']].values     \n",
    "    neg_edgelist1 = edge_df[['head','neg_tail']].values \n",
    "    neg_edgelist2 = edge_df[['neg_head','tail']].values \n",
    "    neg_edgelist = np.concatenate([neg_edgelist1, neg_edgelist2], axis=0)\n",
    "\n",
    "    labels = edge_df['label_indexed'].values \n",
    "    num_labels = max(labels) + 1 if max(labels) > 1 else 1\n",
    "    \n",
    "    tmp_df = pd.DataFrame(pos_edgelist, columns=['drug_index_1', 'drug_index_2'])\n",
    "    merged_df = tmp_df.merge(description_df, on=['drug_index_1', 'drug_index_2'])\n",
    "    \n",
    "    drug_descriptions = merged_df['description'].values\n",
    "    \n",
    "    if use_para:\n",
    "        descriptions = merged_df[['generalized_description',\n",
    "                                  'medical_doctor_1', 'medical_doctor_2','medical_doctor_3', \n",
    "                                  'pharmacologist_1', 'pharmacologist_2','pharmacologist_3', \n",
    "                                  'toxicologist_1', 'toxicologist_2', 'toxicologist_3']].values\n",
    "    else:\n",
    "        descriptions = merged_df['generalized_description'].values\n",
    "        \n",
    "    label_text = merged_df[['label']].values\n",
    "            \n",
    "    full_descriptions = np.concatenate((descriptions, descriptions, descriptions))\n",
    "    full_drug_descriptions = np.concatenate([drug_descriptions]*3)\n",
    "    label_text = np.concatenate([label_text]*3)\n",
    "    \n",
    "    edgelist = np.concatenate((pos_edgelist, neg_edgelist))\n",
    "    labels = np.concatenate((labels, labels, labels))\n",
    "    pos_neg = np.concatenate((np.ones((pos_edgelist.shape[0])), np.zeros((neg_edgelist1.shape[0])), np.zeros((neg_edgelist2.shape[0]))))\n",
    "    \n",
    "    return full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, label_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_df(split, description_df):\n",
    "    full_descriptions, full_drug_descriptions, edgelist, labels, pos_neg, label_text = get_ddi_info(split, description_df, use_para=True)\n",
    "    df = pd.DataFrame({'head': edgelist[:,0], 'tail': edgelist[:,1], 'labels': labels, 'pos_neg': pos_neg,\n",
    "                       'descriptions_0': full_descriptions[:,0], 'label_descriptions': label_text[:,0], \n",
    "                       'descriptions_1': full_descriptions[:,1],\n",
    "                       'descriptions_2': full_descriptions[:,2],\n",
    "                       'descriptions_3': full_descriptions[:,3],\n",
    "                       'descriptions_4': full_descriptions[:,4],\n",
    "                       'descriptions_5': full_descriptions[:,5],\n",
    "                       'descriptions_6': full_descriptions[:,6],\n",
    "                       'descriptions_7': full_descriptions[:,7],\n",
    "                       'descriptions_8': full_descriptions[:,8],\n",
    "                       'descriptions_9': full_descriptions[:,9]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95e523ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_new_df('train', description_df)\n",
    "val_df = get_new_df('val', description_df)\n",
    "test_df = get_new_df('test', description_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "711dd32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = pd.concat([val_df, test_df], ignore_index=True)\n",
    "eval_df = eval_df.sample(frac=1).reset_index(drop=True)\n",
    "eval_df.to_csv('./paraphrased_dataset_new/eval_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "068b3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df.to_csv('./paraphrased_dataset_new/train_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "madrigal_env (cuda11.7)",
   "language": "python",
   "name": "madrigal_env_cuda117"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
