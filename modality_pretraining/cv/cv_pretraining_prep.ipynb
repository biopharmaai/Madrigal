{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213e95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from madrigal.models.models import MLPEncoder\n",
    "from madrigal.utils import DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e4841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, vae_encoder_params: dict, hidden_dim: int, latent_dim: int, vae_decoder_params: dict):\n",
    "        super(VAE, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.encoder = MLPEncoder(**vae_encoder_params)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.decoder = MLPEncoder(**vae_decoder_params)  # while it is an MLPEncoder object, it is actually a decoder\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.encoder(x))\n",
    "        return self.fc_mu(h), self.fc_var(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "        # return torch.tanh(self.decoder(z))  # TODO: validate the range of perturbation values\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return z, recon, mu, logvar\n",
    "    \n",
    "    def loss(self, recons, x, mu, logvar):\n",
    "        \"\"\"ELBO assuming entries of x are binary variables, with closed form KLD.\"\"\"\n",
    "        \n",
    "        recons_loss= F.mse_loss(recons, x)\n",
    "        kld_loss=torch.mean(-0.5 * torch.sum(1 + logvar - mu ** 2 - logvar.exp(), dim = 1), dim = 0)\n",
    "\n",
    "        return recons_loss + kld_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3513635",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, ae_encoder_params: dict, ae_decoder_params: dict):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoder = MLPEncoder(**ae_encoder_params)\n",
    "        self.decoder = MLPEncoder(**ae_decoder_params)  # while it is an MLPEncoder object, it is actually a decoder\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.encoder(x))\n",
    "        return h\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "        # return torch.tanh(self.decoder(z))  # TODO: validate the range of perturbation values\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.encode(x))\n",
    "        recon = self.decode(h)\n",
    "        return h, recon\n",
    "    \n",
    "    def loss(self, recons, x):\n",
    "        recons_loss= F.mse_loss(recons, x)\n",
    "        return recons_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8014d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = pd.read_csv(DATA_DIR+'views_features_new/cv/cv_cp_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_between = pd.read_csv(DATA_DIR+'polypharmacy/DrugBank/split_by_drugs_random/test_between_df.csv')\n",
    "test_within = pd.read_csv(DATA_DIR+'polypharmacy/DrugBank/split_by_drugs_random/test_within_df.csv')\n",
    "\n",
    "all_smiles = pd.read_csv(DATA_DIR+'views_features/combined_metadata_reindexed_ddi.csv')\n",
    "all_smiles = all_smiles.canonical_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c87c5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.concatenate((test_between['head'].values, test_within['head'].values, test_within['tail'].values ))\n",
    "test = np.unique(test)\n",
    "test_smiles = all_smiles.loc[test].values\n",
    "\n",
    "overlap = np.intersect1d(cv.columns, test_smiles)\n",
    "cv = cv[cv.columns.difference(overlap)]\n",
    "cv = cv[cv.columns.drop(list(cv.filter(regex='Unnamed')))]\n",
    "\n",
    "cv.to_csv('cv_no_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f003a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class CVDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_file):\n",
    "        self.df = pd.read_csv(data_file, index_col=0)\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[1]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        item = self.df.iloc[:,index]\n",
    "        return torch.tensor(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bcc0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CVDataset('cv_no_test.csv')\n",
    "\n",
    "train_length=int(0.8* len(dataset))\n",
    "test_length=len(dataset)-train_length\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset,(train_length,test_length))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "196409ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training at epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 27/27 [00:05<00:00,  4.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5102753043174744\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.34106629117754694\n",
      "Training at epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 27/27 [00:05<00:00,  4.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.30785658955574036\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2573168741283297\n",
      "Training at epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 27/27 [00:05<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.29913127422332764\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2531611630551279\n",
      "Training at epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 27/27 [00:05<00:00,  4.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2922775447368622\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.26249992536556266\n",
      "Training at epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 27/27 [00:05<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.29167234897613525\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2506233064018257\n",
      "Training at epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 27/27 [00:05<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.28825557231903076\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.24849607025472054\n",
      "Training at epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 27/27 [00:05<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.28548455238342285\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.24797853691229146\n",
      "Training at epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 27/27 [00:05<00:00,  4.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2831953763961792\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2497517443389612\n",
      "Training at epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 27/27 [00:05<00:00,  4.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.2808248996734619\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.24528804807880883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder_params ={'in_dim': 559, 'hidden_dims': [512, 256], 'output_dim': 128, 'p':0.2, \n",
    "                 'norm': 'bn', 'actn': 'relu', 'order': 'nd'}\n",
    "decoder_params = {'in_dim': 128, 'hidden_dims': [256, 512], 'output_dim': 559, 'p':0.2, \n",
    "                 'norm': 'bn', 'actn': 'relu', 'order': 'nd'}\n",
    "\n",
    "model =  AE(encoder_params, ae_decoder_params = decoder_params)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='sum')\n",
    "\n",
    "def train(x):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z, recon = model(x)\n",
    "    loss = model.loss(recon, x)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "    \n",
    "@torch.no_grad()\n",
    "def test(test_loader):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    for x in tqdm(test_loader):\n",
    "        z, recon = model(x.float())\n",
    "        loss = model.loss(recon, x)\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    print(f'Loss: {np.array(losses).ravel().mean()}')\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    print(f'Training at epoch {epoch}')\n",
    "    losses = []\n",
    "    for batch in tqdm(train_loader):\n",
    "        loss = train(batch.float())\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    print(f'Loss: {np.array(losses).ravel().mean()}')\n",
    "\n",
    "    print('Testing')\n",
    "    test(test_loader)\n",
    "    \n",
    "torch.save(model.encoder.state_dict(), 'cv_model_ae.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9f85000",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def plot_test(test_loader):\n",
    "    xs = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    for x in tqdm(test_loader):\n",
    "        z, recon = model(x.float())\n",
    "        xs.append(x.detach().cpu().numpy())\n",
    "        preds.append(recon.detach().cpu().numpy())\n",
    "    return np.array(xs), np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5e308b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "x,pred = plot_test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b0e461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.concatenate([x,pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f6c3e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cv_arr.npy', arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchdrug",
   "language": "python",
   "name": "torchdrug"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
