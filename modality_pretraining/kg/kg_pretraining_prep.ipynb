{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697e5a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:15:19   Note: NumExpr detected 28 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "import sys\n",
    "sys.path.append('/n/data1/hms/dbmi/zitnik/lab/users/vau974/NovelDDI/')\n",
    "from novelddi.models import models\n",
    "from torch import nn\n",
    "import copy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75df7906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vau974/.conda/envs/novelddi/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3398: DtypeWarning: Columns (1,2,3,4,5,6,7,10,11,12,13,14,28,29) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "kg = pd.read_csv('/n/data1/hms/dbmi/zitnik/lab/users/yeh803/DDI/PrimeKG/kg.csv')\n",
    "meta = pd.read_csv('/n/data1/hms/dbmi/zitnik/lab/users/yeh803/DDI/processed_data/views_features/combined_metadata_reindexed_ddi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "755ec604",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_kg = meta[meta.view_kg == 1].node_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26d6ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = kg[kg.x_id.isin(in_kg)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "019c0363",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = kg.groupby('x_id')['x_id'].count().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85edcdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('counts.npy', np.array(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e758788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2030/3999057193.py:3: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(counts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "654ae84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIEWS_PATH = '/n/data1/hms/dbmi/zitnik/lab/users/yeh803/DDI/processed_data/views_features/KG_data_hgt.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fa2ddd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = torch.load(VIEWS_PATH)\n",
    "graph_copy = copy.deepcopy(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e22405c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rev_added = []\n",
    "# for edge in graph.edge_types:\n",
    "#     if edge[0] == edge[2]:\n",
    "#         x = graph[edge[0], edge[1], edge[2]].edge_index\n",
    "#         x = torch.roll(x, 1, 0)\n",
    "#         rev_added.append((edge[0], 'rev_' + edge[1], edge[2]))\n",
    "#         graph[edge[0], 'rev_' + edge[1], edge[2]].edge_index = x\n",
    "#         #graph[edge[0], 'rev_' + edge[1], edge[2]].edge_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "566a51d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_types = []\n",
    "rev_edge_types = []\n",
    "for edge in graph.edge_types:\n",
    "    if 'rev' not in edge[1]:\n",
    "        edge_types.append(edge)\n",
    "        rev_edge_types.append(None)\n",
    "        #rev_edge_types.append( (edge[2], 'rev_' + edge[1] ,edge[0])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4586ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    is_undirected = False,\n",
    "    disjoint_train_ratio=0.1,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,\n",
    "    edge_types=edge_types,\n",
    "    rev_edge_types=rev_edge_types, \n",
    ")\n",
    "train_data, val_data, test_data = transform(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8901fec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_rev(data):\n",
    "#     for edge in data.edge_types:\n",
    "#         if edge in rev_added:\n",
    "#             del data[edge]\n",
    "        \n",
    "# remove_rev(train_data)\n",
    "# remove_rev(val_data)\n",
    "# remove_rev(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed9a12cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manually_add_rev_labels(data):\n",
    "    for edge in data.edge_types:\n",
    "        if 'rev' in edge[1]:\n",
    "            normal_edge = edge[1].replace(\"rev_\", \"\")\n",
    "            normal = (edge[2], normal_edge, edge[0])\n",
    "            normal_edge_index = data[normal].edge_label_index\n",
    "            data[edge]['edge_label_index'] = torch.roll(normal_edge_index, 1, 0)\n",
    "            data[edge]['edge_label'] = data[normal].edge_label\n",
    "\n",
    "def manually_add_rev_labels_2(data):\n",
    "    for edge in data.edge_types:\n",
    "        if 'rev' in edge[1]:\n",
    "            pos = data[edge]['edge_index']\n",
    "            #neg = torch.stack([torch.arange(data[edge]['edge_index'].max()), \n",
    "                               #torch.randperm(data[edge]['edge_index'].max())], dim=0)\n",
    "            #data[edge]['edge_label_index'] = torch.cat([pos, neg], axis=1)\n",
    "            data[edge]['edge_label_index'] = pos\n",
    "            data[edge]['edge_label'] = torch.ones(pos.shape[1])\n",
    "            #data[edge]['edge_label'] = torch.cat([torch.ones(pos.shape[1]), torch.zeros(neg.shape[1])])\n",
    "            \n",
    "manually_add_rev_labels(train_data)\n",
    "manually_add_rev_labels(val_data)\n",
    "manually_add_rev_labels(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62a6013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_edge_label_index = [ (train_data[edge]['edge_label_index'],edge) for edge in train_data.edge_types]\n",
    "val_edge_label_index = [ (val_data[edge]['edge_label_index'],edge) for edge in val_data.edge_types]\n",
    "test_edge_label_index = [ (test_data[edge]['edge_label_index'],edge) for edge in test_data.edge_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0300d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data(data):\n",
    "    for edge in data.edge_types:\n",
    "        left = data[edge[0]]['num_nodes']\n",
    "        right = data[edge[2]]['num_nodes']\n",
    "        \n",
    "        edge_index = data[edge]['edge_index']\n",
    "#         print(edge)\n",
    "#         print(edge_index[0,:].max(), left)\n",
    "#         print(edge_index[1,:].max(), right)\n",
    "        if edge_index[0,:].max() > left: print('hi')\n",
    "        if edge_index[1,:].max() > right: print('hi')\n",
    "\n",
    "check_data(train_data)\n",
    "check_data(val_data)\n",
    "check_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49e1de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HGTLinkPred(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, num_heads, \n",
    "                 metadata, num_edge_types, group='sum'):\n",
    "        super(HGTLinkPred, self).__init__()\n",
    "        \n",
    "        self.encoder = models.HGT(in_channels, hidden_channels, out_channels, \n",
    "                                  num_layers, num_heads, metadata, group)\n",
    "        self.decoder = models.BilinearDDIScorer(out_channels, out_channels, 1)\n",
    "        self.decoders = [self.decoder for i in range(num_edge_types)]\n",
    "    \n",
    "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
    "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
    "        preds = []\n",
    "        for decoder, (edge_pred_index, edge_name) in zip(self.decoders, edge_label_index):\n",
    "            i, r, j = edge_name\n",
    "            print(edge_name)\n",
    "            node_in, node_out = edge_pred_index\n",
    "            pred = decoder(z_dict[i], z_dict[j]).squeeze(0)\n",
    "            pred = pred[node_in, node_out]\n",
    "            preds.append(pred)\n",
    "        return torch.cat(preds, 0)\n",
    "    \n",
    "    def save_checkpoint(self, PATH):\n",
    "        torch.save(self.encoder.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "67891bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = HGTLinkPred(in_channels=train_data.x_dict['drug'].shape[1],\n",
    "                    hidden_channels=128,\n",
    "                    out_channels=128,\n",
    "                    num_layers=2,\n",
    "                    num_heads=4,\n",
    "                    num_edge_types=len(train_edge_label_index),\n",
    "                    metadata = train_data.metadata()).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    preds = model(train_data.x_dict, train_data.edge_index_dict, train_edge_label_index)\n",
    "    targets = torch.stack([i[0] for i in train_edge_label_index], 0)\n",
    "    loss = loss_fn(pred, target) \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c772676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('anatomy', 'anatomy_anatomy', 'anatomy')\n",
      "('gene/protein', 'anatomy_protein_absent', 'anatomy')\n",
      "('anatomy', 'rev_anatomy_protein_absent', 'gene/protein')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m301\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_edge_label_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m train_edge_label_index], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, target) \n",
      "File \u001b[0;32m~/.conda/envs/novelddi/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mHGTLinkPred.forward\u001b[0;34m(self, x_dict, edge_index_dict, edge_label_index)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(edge_name)\n\u001b[1;32m     17\u001b[0m node_in, node_out \u001b[38;5;241m=\u001b[39m edge_pred_index\n\u001b[0;32m---> 18\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred[node_in, node_out]\n\u001b[1;32m     20\u001b[0m preds\u001b[38;5;241m.\u001b[39mappend(pred)\n",
      "File \u001b[0;32m~/.conda/envs/novelddi/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/n/data1/hms/dbmi/zitnik/lab/users/vau974/NovelDDI/novelddi/models/models.py:363\u001b[0m, in \u001b[0;36mBilinearDDIScorer.forward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input1: torch\u001b[38;5;241m.\u001b[39mTensor, input2: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 363\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbilinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/n/data1/hms/dbmi/zitnik/lab/users/vau974/NovelDDI/novelddi/models/models.py:360\u001b[0m, in \u001b[0;36mBilinearDDIScorer.bilinear\u001b[0;34m(self, input1, input2, weight, bias)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbilinear\u001b[39m(\u001b[38;5;28mself\u001b[39m, input1: torch\u001b[38;5;241m.\u001b[39mTensor, input2: torch\u001b[38;5;241m.\u001b[39mTensor, weight: torch\u001b[38;5;241m.\u001b[39mTensor, bias: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# NOTE: weight is [num_labels, dim1, dim2]. since broadcasting applies to the first dim, we don't need to worry about the broadcasting of inputs across labels (see https://pytorch.org/docs/stable/generated/torch.matmul.html)\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m bias\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 301):\n",
    "    loss = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de3c66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "novelddi",
   "language": "python",
   "name": "novelddi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
